<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Formation sur les Infrastructures Big Data"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/formation-bigdata/tp4/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>Partie 4 - Traitement par Lot avec Spark - Formation Big Data</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#ef5552><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=red data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#objectifs class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Formation Big Data" class="md-header__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Formation Big Data </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Partie 4 - Traitement par Lot avec Spark </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Formation Big Data" class="md-nav__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Formation Big Data </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../tp1/ class=md-nav__link> Partie 1 - Hadoop HDFS </a> </li> <li class=md-nav__item> <a href=../tp2/ class=md-nav__link> Partie 2 - Hadoop Map Reduce </a> </li> <li class=md-nav__item> <a href=../tp3/ class=md-nav__link> Partie 3 - Spark Shell </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Partie 4 - Traitement par Lot avec Spark <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Partie 4 - Traitement par Lot avec Spark </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#preparation-de-lenvironnement-et-code class=md-nav__link> Préparation de l'environnement et Code </a> </li> <li class=md-nav__item> <a href=#test-du-code-en-local class=md-nav__link> Test du code en local </a> </li> <li class=md-nav__item> <a href=#lancement-du-code-sur-le-cluster class=md-nav__link> Lancement du code sur le cluster </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tp5/ class=md-nav__link> Partie 5 - Traitement Streaming avec Spark </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#preparation-de-lenvironnement-et-code class=md-nav__link> Préparation de l'environnement et Code </a> </li> <li class=md-nav__item> <a href=#test-du-code-en-local class=md-nav__link> Test du code en local </a> </li> <li class=md-nav__item> <a href=#lancement-du-code-sur-le-cluster class=md-nav__link> Lancement du code sur le cluster </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/formation-bigdata/edit/master/docs/tp4.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>Partie 4 - Traitement par Lot avec Spark</h1> <p><center><img src=../img/tp4/spark-batch.png width=500></center></p> <h3 id=objectifs>Objectifs<a class=headerlink href=#objectifs title="Permanent link">&para;</a></h3> <p>Utilisation de Spark pour lancer un traitement par lot sur un fichier sur HDFS. </p> <h3 id=preparation-de-lenvironnement-et-code>Préparation de l'environnement et Code<a class=headerlink href=#preparation-de-lenvironnement-et-code title="Permanent link">&para;</a></h3> <p>Nous allons dans cette partie créer un projet Spark Batch en Java (un simple WordCount), le charger sur le cluster et lancer le job.</p> <ol> <li>Créer un projet Maven avec IntelliJ intitulé <em>2-Spark-Batch</em>, en utilisant la config suivante:<ul> <li><strong>GroupId</strong>: spark.mapreduce</li> <li><strong>ArtifactId</strong>: wordcount-spark</li> <li><strong>Version</strong>: 1</li> </ul> </li> <li>Rajouter dans le fichier pom les dépendances nécessaires, et indiquer la version du compilateur Java: <div class=highlight><pre><span></span><code><span class=nt>&lt;properties&gt;</span>
    <span class=nt>&lt;maven.compiler.source&gt;</span>1.8<span class=nt>&lt;/maven.compiler.source&gt;</span>
    <span class=nt>&lt;maven.compiler.target&gt;</span>1.8<span class=nt>&lt;/maven.compiler.target&gt;</span>
<span class=nt>&lt;/properties&gt;</span>
<span class=nt>&lt;dependencies&gt;</span>
    <span class=nt>&lt;dependency&gt;</span>
        <span class=nt>&lt;groupId&gt;</span>org.apache.spark<span class=nt>&lt;/groupId&gt;</span>
        <span class=nt>&lt;artifactId&gt;</span>spark-core_2.13<span class=nt>&lt;/artifactId&gt;</span>
        <span class=nt>&lt;version&gt;</span>3.5.0<span class=nt>&lt;/version&gt;</span>
    <span class=nt>&lt;/dependency&gt;</span>
    <span class=nt>&lt;dependency&gt;</span>
        <span class=nt>&lt;groupId&gt;</span>org.slf4j<span class=nt>&lt;/groupId&gt;</span>
        <span class=nt>&lt;artifactId&gt;</span>slf4j-reload4j<span class=nt>&lt;/artifactId&gt;</span>
        <span class=nt>&lt;version&gt;</span>2.1.0-alpha1<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;scope&gt;</span>test<span class=nt>&lt;/scope&gt;</span>
    <span class=nt>&lt;/dependency&gt;</span>
<span class=nt>&lt;/dependencies&gt;</span>
</code></pre></div></li> <li>Sous le répertoire java, créer un package que vous appellerez <em>spark.batch</em>, et dedans, une classe appelée <em>WordCountTask</em>.</li> <li> <p>Écrire le code suivant dans <em>WordCountTask.java</em> : <div class=highlight><pre><span></span><code><span class=kn>package</span> <span class=nn>spark.batch</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>org.apache.spark.SparkConf</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.api.java.JavaPairRDD</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.api.java.JavaRDD</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.api.java.JavaSparkContext</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.slf4j.Logger</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.slf4j.LoggerFactory</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>scala.Tuple2</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>java.util.Arrays</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>com.google.common.base.Preconditions</span><span class=p>;</span>

<span class=kd>public</span> <span class=kd>class</span> <span class=nc>WordCountTask</span> <span class=p>{</span>
      <span class=kd>private</span> <span class=kd>static</span> <span class=kd>final</span> <span class=n>Logger</span> <span class=n>LOGGER</span> <span class=o>=</span> <span class=n>LoggerFactory</span><span class=p>.</span><span class=na>getLogger</span><span class=p>(</span><span class=n>WordCountTask</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>

      <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=p>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=p>)</span> <span class=p>{</span>
          <span class=n>Preconditions</span><span class=p>.</span><span class=na>checkArgument</span><span class=p>(</span><span class=n>args</span><span class=p>.</span><span class=na>length</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>,</span> <span class=s>&quot;Please provide the path of input file and output dir as parameters.&quot;</span><span class=p>);</span>
          <span class=k>new</span> <span class=n>WordCountTask</span><span class=p>().</span><span class=na>run</span><span class=p>(</span><span class=n>args</span><span class=o>[</span><span class=mi>0</span><span class=o>]</span><span class=p>,</span> <span class=n>args</span><span class=o>[</span><span class=mi>1</span><span class=o>]</span><span class=p>);</span>
      <span class=p>}</span>

      <span class=kd>public</span> <span class=kt>void</span> <span class=nf>run</span><span class=p>(</span><span class=n>String</span> <span class=n>inputFilePath</span><span class=p>,</span> <span class=n>String</span> <span class=n>outputDir</span><span class=p>)</span> <span class=p>{</span>
          <span class=n>String</span> <span class=n>master</span> <span class=o>=</span> <span class=s>&quot;local[*]&quot;</span><span class=p>;</span>
          <span class=n>SparkConf</span> <span class=n>conf</span> <span class=o>=</span> <span class=k>new</span> <span class=n>SparkConf</span><span class=p>()</span>
                  <span class=p>.</span><span class=na>setAppName</span><span class=p>(</span><span class=n>WordCountTask</span><span class=p>.</span><span class=na>class</span><span class=p>.</span><span class=na>getName</span><span class=p>())</span>
                  <span class=p>.</span><span class=na>setMaster</span><span class=p>(</span><span class=n>master</span><span class=p>);</span>
          <span class=n>JavaSparkContext</span> <span class=n>sc</span> <span class=o>=</span> <span class=k>new</span> <span class=n>JavaSparkContext</span><span class=p>(</span><span class=n>conf</span><span class=p>);</span>

          <span class=n>JavaRDD</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span> <span class=n>textFile</span> <span class=o>=</span> <span class=n>sc</span><span class=p>.</span><span class=na>textFile</span><span class=p>(</span><span class=n>inputFilePath</span><span class=p>);</span>
          <span class=n>JavaPairRDD</span><span class=o>&lt;</span><span class=n>String</span><span class=p>,</span> <span class=n>Integer</span><span class=o>&gt;</span> <span class=n>counts</span> <span class=o>=</span> <span class=n>textFile</span>
                  <span class=p>.</span><span class=na>flatMap</span><span class=p>(</span><span class=n>s</span> <span class=o>-&gt;</span> <span class=n>Arrays</span><span class=p>.</span><span class=na>asList</span><span class=p>(</span><span class=n>s</span><span class=p>.</span><span class=na>split</span><span class=p>(</span><span class=s>&quot; &quot;</span><span class=p>)).</span><span class=na>iterator</span><span class=p>())</span>
                  <span class=p>.</span><span class=na>mapToPair</span><span class=p>(</span><span class=n>word</span> <span class=o>-&gt;</span> <span class=k>new</span> <span class=n>Tuple2</span><span class=o>&lt;&gt;</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
                  <span class=p>.</span><span class=na>reduceByKey</span><span class=p>((</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span><span class=p>);</span>
          <span class=n>counts</span><span class=p>.</span><span class=na>saveAsTextFile</span><span class=p>(</span><span class=n>outputDir</span><span class=p>);</span>
      <span class=p>}</span>
  <span class=p>}</span>
</code></pre></div> La première chose à faire dans un programme Spark est de créer un objet <em>JavaSparkContext</em>, qui indique à Spark comment accéder à un cluster. Pour créer ce contexte, vous aurez besoin de construire un objet <em>SparkConf</em> qui contient toutes les informations sur l'application.</p> <ul> <li><em>appName</em> est le nom de l'application</li> <li><em>master</em> est une URL d'un cluster Spark, Mesos ou YARN, ou bien une chaîne spéciale <em>local</em> pour lancer le job en mode local.</li> </ul> </li> </ol> <div class="admonition warning"> <p class=admonition-title>Warning</p> <p>Nous avons indiqué ici que notre master est <em>local</em> pour les besoins du test, mais plus tard, en le packageant pour le cluster, nous allons enlever cette indication. Il est en effet déconseillé de la hard-coder dans le programme, il faudrait plutôt l'indiquer comme option de commande à chaque fois que nous lançons le job.</p> <p>Le reste du code de l'application est la version en Java de l'exemple en scala que nous avions fait avec <a href=../tp3>spark-shell</a>.</p> </div> <h3 id=test-du-code-en-local>Test du code en local<a class=headerlink href=#test-du-code-en-local title="Permanent link">&para;</a></h3> <p>Pour tester le code sur votre machine, procéder aux étapes suivantes:</p> <ol> <li>Insérer un fichier texte de votre choix (par exemple le fameux <a href=https://generator.lorem-ipsum.info/ >loremipsum.txt</a>) dans le répertoire src/main/resources.</li> <li>Lancer le programme en utilisant les arguments suivants:<ol> <li><strong>Arg1</strong>: le chemin du fichier <em>loremipsum.txt</em></li> <li><strong>Arg2</strong>: le chemin d'un répertoire <em>out</em> sous <em>resources</em> (vous ne devez pas le créer)</li> </ol> </li> <li>Cliquer sur OK, et lancer la configuration. Si tout se passe bien, un répertoire <em>out</em> sera créé sous <em>resources</em>, qui contient (entre autres) deux fichiers: part-00000, part-00001.</li> </ol> <p><center><img src=../img/tp4/resultat-batch-local.png width=200></center></p> <h3 id=lancement-du-code-sur-le-cluster>Lancement du code sur le cluster<a class=headerlink href=#lancement-du-code-sur-le-cluster title="Permanent link">&para;</a></h3> <p>Pour exécuter le code sur le cluster, modifier comme indiqué les lignes en jaune dans ce qui suit:</p> <div class=highlight><pre><span></span><code><span class=kd>public</span> <span class=kd>class</span> <span class=nc>WordCountTask</span> <span class=p>{</span>
  <span class=kd>private</span> <span class=kd>static</span> <span class=kd>final</span> <span class=n>Logger</span> <span class=n>LOGGER</span> <span class=o>=</span> <span class=n>LoggerFactory</span><span class=p>.</span><span class=na>getLogger</span><span class=p>(</span><span class=n>WordCountTask</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>

  <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=p>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=p>)</span> <span class=p>{</span>
      <span class=n>Preconditions</span><span class=p>.</span><span class=na>checkArgument</span><span class=p>(</span><span class=n>args</span><span class=p>.</span><span class=na>length</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>,</span> <span class=s>&quot;Please provide the path of input file and output dir as parameters.&quot;</span><span class=p>);</span>
      <span class=k>new</span> <span class=n>WordCountTask</span><span class=p>().</span><span class=na>run</span><span class=p>(</span><span class=n>args</span><span class=o>[</span><span class=mi>0</span><span class=o>]</span><span class=p>,</span> <span class=n>args</span><span class=o>[</span><span class=mi>1</span><span class=o>]</span><span class=p>);</span>
  <span class=p>}</span>

  <span class=kd>public</span> <span class=kt>void</span> <span class=nf>run</span><span class=p>(</span><span class=n>String</span> <span class=n>inputFilePath</span><span class=p>,</span> <span class=n>String</span> <span class=n>outputDir</span><span class=p>)</span> <span class=p>{</span>

<span class=hll>      <span class=n>SparkConf</span> <span class=n>conf</span> <span class=o>=</span> <span class=k>new</span> <span class=n>SparkConf</span><span class=p>()</span>
</span><span class=hll>              <span class=p>.</span><span class=na>setAppName</span><span class=p>(</span><span class=n>WordCountTask</span><span class=p>.</span><span class=na>class</span><span class=p>.</span><span class=na>getName</span><span class=p>());</span>
</span>
      <span class=n>JavaSparkContext</span> <span class=n>sc</span> <span class=o>=</span> <span class=k>new</span> <span class=n>JavaSparkContext</span><span class=p>(</span><span class=n>conf</span><span class=p>);</span>

      <span class=n>JavaRDD</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span> <span class=n>textFile</span> <span class=o>=</span> <span class=n>sc</span><span class=p>.</span><span class=na>textFile</span><span class=p>(</span><span class=n>inputFilePath</span><span class=p>);</span>
      <span class=n>JavaPairRDD</span><span class=o>&lt;</span><span class=n>String</span><span class=p>,</span> <span class=n>Integer</span><span class=o>&gt;</span> <span class=n>counts</span> <span class=o>=</span> <span class=n>textFile</span>
<span class=hll>              <span class=p>.</span><span class=na>flatMap</span><span class=p>(</span><span class=n>s</span> <span class=o>-&gt;</span> <span class=n>Arrays</span><span class=p>.</span><span class=na>asList</span><span class=p>(</span><span class=n>s</span><span class=p>.</span><span class=na>split</span><span class=p>(</span><span class=s>&quot;\t&quot;</span><span class=p>)).</span><span class=na>iterator</span><span class=p>())</span>
</span>              <span class=p>.</span><span class=na>mapToPair</span><span class=p>(</span><span class=n>word</span> <span class=o>-&gt;</span> <span class=k>new</span> <span class=n>Tuple2</span><span class=o>&lt;&gt;</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
              <span class=p>.</span><span class=na>reduceByKey</span><span class=p>((</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>a</span> <span class=o>+</span> <span class=n>b</span><span class=p>);</span>
      <span class=n>counts</span><span class=p>.</span><span class=na>saveAsTextFile</span><span class=p>(</span><span class=n>outputDir</span><span class=p>);</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <p>Lancer ensuite une configuration de type Maven, avec la commande <em>package</em>. Un fichier intitulé <em>wordcount-spark-1.jar</em> sera créé sous le répertoire target.</p> <p>Nous allons maintenant copier ce fichier dans docker. Pour cela, naviguer vers le répertoire du projet avec votre terminal (ou plus simplement utiliser le terminal dans VSCode), et taper la commande suivante:</p> <div class=highlight><pre><span></span><code>docker cp target/wordcount-spark-1.jar hadoop-master:/root/wordcount-spark.jar
</code></pre></div> <p>Revenir à votre contenaire master, et lancer un job Spark en utilisant ce fichier jar généré, avec la commande <code>spark-submit</code>, un script utilisé pour lancer des applications spark sur un cluster.</p> <div class=highlight><pre><span></span><code>spark-submit  --class spark.batch.WordCountTask --master <span class=nb>local</span> wordcount-spark.jar input/purchases.txt out-spark
</code></pre></div> <ul> <li>Nous allons lancer le job en mode local, pour commencer.</li> <li>Le fichier en entrée est le fichier purchases.txt (que vous déjà chargé dans HDFS dans le TP précédent), et le résultat sera stocké dans un nouveau répertoire <em>out-spark</em>.</li> </ul> <div class="admonition warning"> <p class=admonition-title>Attention</p> <p>Vérifiez bien que le fichier <em>purchases</em> existe dans le répertoire input de HDFS (et que le répertoire <em>out-spark</em> n'existe pas)! Si ce n'est pas le cas, vous pouvez le charger avec les commandes suivantes: <div class=highlight><pre><span></span><code>hdfs dfs -mkdir -p input
hdfs dfs -put purchases.txt input
</code></pre></div></p> </div> <p>Si tout se passe bien, vous devriez trouver, dans le répertoire <em>out-spark</em>, deux fichiers part-00000 et part-00001, qui ressemblent à ce qui suit:</p> <p><center><img src=../img/tp4/output-batch.png width=300></center></p> <p>Nous allons maintenant tester le comportement de <em>spark-submit</em> si on l'exécute en mode <em>cluster</em> sur YARN. Pour cela, exécuter le code suivant: <div class=highlight><pre><span></span><code>spark-submit  --class spark.batch.WordCountTask --master yarn --deploy-mode cluster wordcount-spark.jar input/purchases.txt out-spark2
</code></pre></div></p> <ul> <li>En lançant le job sur Yarn, deux modes de déploiement sont possibles:<ul> <li><strong>Mode cluster</strong>: où tout le job s'exécute dans le cluster, c'est à dire les Spark Executors (qui exécutent les vraies tâches) et le Spark Driver (qui ordonnance les Executors). Ce dernier sera encapsulé dans un YARN Application Master.</li> <li><strong>Mode client</strong> : où Spark Driver s'exécute sur la machine cliente (tel que votre propre ordinateur portable). Si votre machine s'éteint, le job s'arrête. Ce mode est approprié pour les jobs interactifs.</li> </ul> </li> </ul> <p>Si tout se passe bien, vous devriez obtenir un répertoire out-spark2 dans HDFS avec les fichiers usuels.</p> <details class=bug> <summary>En cas d'erreur: consulter les logs!</summary> <p>En cas d'erreur ou d'interruption du job sur Yarn, vous pourrez consulter les fichiers logs pour chercher le message d'erreur (le message affiché sur la console n'est pas assez explicite). Pour cela, sur votre navigateur, aller à l'adresse: <code>http://localhost:8041/logs/userlogs</code>et suivez toujours les derniers liens jusqu'à <em>stderr</em>.</p> </details> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2024-05-24T13:55:49+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-05-24</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../tp3/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Partie 3 - Spark Shell" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Partie 3 - Spark Shell </div> </div> </a> <a href=../tp5/ class="md-footer__link md-footer__link--next" aria-label="Next: Partie 5 - Traitement Streaming avec Spark" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Partie 5 - Traitement Streaming avec Spark </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>