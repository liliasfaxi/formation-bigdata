<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Formation sur les Infrastructures Big Data"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/formation-bigdata/tp1/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>Partie 1 - Hadoop HDFS - Formation Big Data</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#ef5552><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=red data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#objectifs class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Formation Big Data" class="md-header__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Formation Big Data </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Partie 1 - Hadoop HDFS </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Formation Big Data" class="md-nav__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Formation Big Data </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Partie 1 - Hadoop HDFS <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Partie 1 - Hadoop HDFS </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#hadoop class=md-nav__link> Hadoop </a> <nav class=md-nav aria-label=Hadoop> <ul class=md-nav__list> <li class=md-nav__item> <a href=#presentation class=md-nav__link> Présentation </a> </li> <li class=md-nav__item> <a href=#hadoop-et-docker class=md-nav__link> Hadoop et Docker </a> </li> <li class=md-nav__item> <a href=#installation class=md-nav__link> Installation </a> </li> <li class=md-nav__item> <a href=#premiers-pas-avec-hadoop class=md-nav__link> Premiers pas avec Hadoop </a> </li> <li class=md-nav__item> <a href=#interfaces-web-pour-hadoop class=md-nav__link> Interfaces web pour Hadoop </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tp2/ class=md-nav__link> Partie 2 - Hadoop Map Reduce </a> </li> <li class=md-nav__item> <a href=../tp3/ class=md-nav__link> Partie 3 - Spark Shell </a> </li> <li class=md-nav__item> <a href=../tp4/ class=md-nav__link> Partie 4 - Traitement par Lot avec Spark </a> </li> <li class=md-nav__item> <a href=../tp5/ class=md-nav__link> Partie 5 - Traitement Streaming avec Spark </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#hadoop class=md-nav__link> Hadoop </a> <nav class=md-nav aria-label=Hadoop> <ul class=md-nav__list> <li class=md-nav__item> <a href=#presentation class=md-nav__link> Présentation </a> </li> <li class=md-nav__item> <a href=#hadoop-et-docker class=md-nav__link> Hadoop et Docker </a> </li> <li class=md-nav__item> <a href=#installation class=md-nav__link> Installation </a> </li> <li class=md-nav__item> <a href=#premiers-pas-avec-hadoop class=md-nav__link> Premiers pas avec Hadoop </a> </li> <li class=md-nav__item> <a href=#interfaces-web-pour-hadoop class=md-nav__link> Interfaces web pour Hadoop </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/formation-bigdata/edit/master/docs/tp1.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>Partie 1 - Hadoop HDFS</h1> <p><center><img alt="Hadoop HDFS" src=../img/tp1/hadoop-hdfs.png></center></p> <h3 id=objectifs>Objectifs<a class=headerlink href=#objectifs title="Permanent link">&para;</a></h3> <p>Initiation au framework hadoop et manipulation de HDFS, utilisation de docker pour lancer un cluster hadoop de 3 noeuds.</p> <h3 id=hadoop>Hadoop<a class=headerlink href=#hadoop title="Permanent link">&para;</a></h3> <h4 id=presentation>Présentation<a class=headerlink href=#presentation title="Permanent link">&para;</a></h4> <p><a href=hadoop.apache.org>Apache Hadoop</a> est un framework open-source pour stocker et traiter les données volumineuses sur un cluster. Il est utilisé par un grand nombre de contributeurs et utilisateurs. Il a une licence Apache 2.0.</p> <p><center><img src=../img/tp1/hadoop.png width=200></center></p> <h4 id=hadoop-et-docker>Hadoop et Docker<a class=headerlink href=#hadoop-et-docker title="Permanent link">&para;</a></h4> <p>Pour déployer le framework Hadoop, nous allons utiliser des contenaires <a href=https://www.docker.com/ >Docker</a>. L'utilisation des contenaires va garantir la consistance entre les environnements de développement et permettra de réduire considérablement la complexité de configuration des machines (dans le cas d'un accès natif) ainsi que la lourdeur d'exécution (si on opte pour l'utilisation d'une machine virtuelle).</p> <h4 id=installation>Installation<a class=headerlink href=#installation title="Permanent link">&para;</a></h4> <p>Nous allons utiliser trois contenaires représentant respectivement un noeud maître (Namenode) et deux noeuds workers (Datanodes).</p> <p>Vous devez pour cela avoir installé docker sur votre machine, et l'avoir correctement configuré. Ensuite, ouvrir la ligne de commande, et taper les instructions suivantes:</p> <ol> <li>Télécharger l'image docker uploadée sur dockerhub: <div class=highlight><pre><span></span><code>docker pull liliasfaxi/my-hadoop-spark:latest
</code></pre></div></li> <li> <p>Créer les trois contenaires à partir de l'image téléchargée. Pour cela:</p> <p>2.1. Créer un réseau qui permettra de relier les trois contenaires: <div class=highlight><pre><span></span><code>docker network create --driver<span class=o>=</span>bridge hadoop
</code></pre></div> 2.2. Créer et lancer les trois contenaires (les instructions -p permettent de faire un mapping entre les ports de la machine hôte et ceux du contenaire):</p> <ul> <li> <p>Contenaire Master: <div class=highlight><pre><span></span><code>docker run -itd --net<span class=o>=</span>hadoop -p <span class=m>9870</span>:9870 -p <span class=m>8088</span>:8088 -p <span class=m>7077</span>:7077 -p <span class=m>16010</span>:16010 --name hadoop-master --hostname hadoop-master liliasfaxi/my-hadoop-spark:latest
</code></pre></div></p> </li> <li> <p>Contenaire Worker 1 <div class=highlight><pre><span></span><code>docker run -itd -p <span class=m>8040</span>:8042 --net<span class=o>=</span>hadoop --name hadoop-worker1 --hostname hadoop-worker1 liliasfaxi/my-hadoop-spark:latest
</code></pre></div></p> </li> <li> <p>Contenaire Worker 2 <div class=highlight><pre><span></span><code>docker run -itd -p <span class=m>8041</span>:8042 --net<span class=o>=</span>hadoop --name hadoop-worker2 --hostname hadoop-worker2 liliasfaxi/my-hadoop-spark:latest
</code></pre></div></p> </li> </ul> <p>2.3. Vérifier que les trois contenaires tournent bien en lançant la commande <code>docker ps</code>. Un résultat semblable au suivant devra s'afficher:</p> <p><center><img src=../img/tp1/running.png></center></p> </li> <li> <p>Entrer dans le contenaire master pour commencer à l'utiliser.</p> <div class=highlight><pre><span></span><code>docker <span class=nb>exec</span> -it hadoop-master bash
</code></pre></div> </li> </ol> <p>Le résultat de cette exécution sera le suivant:</p> <div class=highlight><pre><span></span><code>root@hadoop-master:~#
</code></pre></div> <p>Vous vous retrouverez dans le shell du namenode, et vous pourrez ainsi manipuler le cluster à votre guise. La première chose à faire, une fois dans le contenaire, est de lancer hadoop et yarn. Un script est fourni pour cela, appelé <code>start-hadoop.sh</code>. Lancer ce script.</p> <div class=highlight><pre><span></span><code>./start-hadoop.sh
</code></pre></div> <p>Le résultat devra ressembler à ce qui suit: <img alt="Start Hadoop" src=../img/tp1/start-hadoop.png></p> <p>Vous pouvez visualiser les processus de HDFS et YARN qui tournent sur votre système en lançant la commande <code>jps</code>, qui permet de lister les machines virtuelles Java (JVM) intrumentée sur le système cible. Le résultat que vous devriez obtenir est le suivant:</p> <p><center> <img alt="Jps Master" src=../img/tp1/jps-master.png> </center></p> <p>Exécuter la même instruction sur une machine worker donnera le résultat suivant:</p> <p><center> <img alt="Jps Worker" src=../img/tp1/jps-worker.png> </center></p> <p>On peut voir que les démons Namenode et Secondary Namenode de HDFS, ainsi que le Resource Manager de YARN tournent sur le master, alors que les démons Datanode de HDFS et NodeManager de YARN tournent sur le worker.</p> <h4 id=premiers-pas-avec-hadoop>Premiers pas avec Hadoop<a class=headerlink href=#premiers-pas-avec-hadoop title="Permanent link">&para;</a></h4> <p>Toutes les commandes interagissant avec le système HDFS commencent par <code>hdfs dfs</code>. Ensuite, les options rajoutées sont très largement inspirées des commandes Unix standard.</p> <ul> <li>Créer un répertoire dans HDFS, appelé <em>input</em>. Pour cela, taper: <div class=highlight><pre><span></span><code>hdfs dfs -mkdir -p input
</code></pre></div></li> </ul> <details class=bug> <summary>En cas d'erreur: <em>No such file or directory</em></summary> <p>Si pour une raison ou une autre, vous n'arrivez pas à créer le répertoire <em>input</em>, avec un message ressemblant à ceci: <code>ls: `.': No such file or directory</code>, veiller à construire l'arborescence de l'utilisateur principal (root), comme suit:</p> <p><code>hdfs dfs -mkdir -p /user/root</code></p> </details> <ul> <li>Nous allons utiliser le fichier <a href=https://github.com/CodeMangler/udacity-hadoop-course/blob/ec6bbb839bdc6e701f802c523497fef4e1c206d0/Datasets/purchases.txt.gz>purchases.txt</a> pour manipuler hdfs. </li> <li>Commencer par télécharger le fichier sur votre propre machine, le décompresser, puis par le charger dans le contenaire <code>hadoop-master</code> avec la commande suivante (à exécuter dans le terminal de votre machine hôte): <div class=highlight><pre><span></span><code>docker cp purchases.txt hadoop-master:/root/purchases.txt
</code></pre></div></li> <li>À partir du contenaire master, charger le fichier purchases dans le répertoire input (de HDFS) que vous avez créé: <div class=highlight><pre><span></span><code>hdfs dfs -put purchases.txt input
</code></pre></div></li> <li>Pour afficher le contenu du répertoire <em>input</em>, la commande est: <div class=highlight><pre><span></span><code>hdfs dfs -ls input
</code></pre></div></li> <li>Pour afficher les dernières lignes du fichier purchases: <div class=highlight><pre><span></span><code>hdfs dfs -tail input/purchases.txt
</code></pre></div></li> </ul> <p>Le résultat suivant va donc s'afficher: <center><img src=../img/tp1/purchases-tail.png></center></p> <p>Nous présentons dans le tableau suivant les commandes les plus utilisées pour manipuler les fichiers dans HDFS:</p> <table> <thead> <tr> <th>Instruction</th> <th>Fonctionnalité</th> </tr> </thead> <tbody> <tr> <td><code>hdfs dfs –ls</code></td> <td>Afficher le contenu du répertoire racine</td> </tr> <tr> <td><code>hdfs dfs –put file.txt</code></td> <td>Upload un fichier dans hadoop (à partir du répertoire courant de votre disque local)</td> </tr> <tr> <td><code>hdfs dfs –get file.txt</code></td> <td>Download un fichier à partir de hadoop sur votre disque local</td> </tr> <tr> <td><code>hdfs dfs –tail file.txt</code></td> <td>Lire les dernières lignes du fichier</td> </tr> <tr> <td><code>hdfs dfs –cat file.txt</code></td> <td>Affiche tout le contenu du fichier</td> </tr> <tr> <td><code>hdfs dfs –mv file.txt newfile.txt</code></td> <td>Renommer (ou déplacer) le fichier</td> </tr> <tr> <td><code>hdfs dfs –rm newfile.txt</code></td> <td>Supprimer le fichier</td> </tr> <tr> <td><code>hdfs dfs –mkdir myinput</code></td> <td>Créer un répertoire</td> </tr> </tbody> </table> <h4 id=interfaces-web-pour-hadoop>Interfaces web pour Hadoop<a class=headerlink href=#interfaces-web-pour-hadoop title="Permanent link">&para;</a></h4> <p>Hadoop offre plusieurs interfaces web pour pouvoir observer le comportement de ses différentes composantes. Il est possible d'afficher ces pages directement sur notre machine hôte, et ce grâce à l'utilisation de l'option -p de la commande <code>docker run</code>. En effet, cette option permet de publier un port du contenaire sur la machine hôte. Pour pouvoir publier tous les ports exposés, vous pouvez lancer votre contenaire en utilisant l'option <code>-P</code>.</p> <p>En regardant la commande <code>docker run</code> utilisée plus haut, vous verrez que deux ports de la machine maître ont été exposés:</p> <ul> <li>Le port <strong>9870</strong>: qui permet d'afficher les informations de votre namenode.</li> <li>Le port <strong>8088</strong>: qui permet d'afficher les informations du resource manager de Yarn et visualiser le comportement des différents jobs.</li> </ul> <p>Une fois votre cluster lancé et hadoop démarré et prêt à l'emploi, vous pouvez, sur votre navigateur préféré de votre machine hôte, aller à : <a href=http://localhost:9870>http://localhost:9870</a>. Vous obtiendrez le résultat suivant:</p> <p><img alt="Namenode Info" src=../img/tp1/namenode-info.png></p> <p>À partir de cette interface, il est possible de voir le contenu de votre système de fichier, en cliquant sur <code>Utilities -&gt; Browse the File System</code>. L'interface affichée sera la suivante:</p> <p><img alt="Browse HDFS" src=../img/tp1/browse-hdfs.png></p> <p>Vous pouvez également visualiser l'avancement et les résultats de vos Jobs (Map Reduce ou autre) en allant à l'adresse: <a href=http://localhost:8088>http://localhost:8088</a>.</p> <p><img alt="Resource Manager Info" src=../img/tp1/resourceman-info.png></p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2024-05-19T16:48:14+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-05-19</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../tp2/ class="md-footer__link md-footer__link--next" aria-label="Next: Partie 2 - Hadoop Map Reduce" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Partie 2 - Hadoop Map Reduce </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>