<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Formation sur les Infrastructures Big Data"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/formation-bigdata/tp5/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>Partie 5 - Traitement Streaming avec Spark - Formation Big Data</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#ef5552><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=red data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#objectifs class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Formation Big Data" class="md-header__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Formation Big Data </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Partie 5 - Traitement Streaming avec Spark </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Formation Big Data" class="md-nav__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Formation Big Data </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../tp1/ class=md-nav__link> Partie 1 - Hadoop HDFS </a> </li> <li class=md-nav__item> <a href=../tp2/ class=md-nav__link> Partie 2 - Hadoop Map Reduce </a> </li> <li class=md-nav__item> <a href=../tp3/ class=md-nav__link> Partie 3 - Spark Shell </a> </li> <li class=md-nav__item> <a href=../tp4/ class=md-nav__link> Partie 4 - Traitement par Lot avec Spark </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Partie 5 - Traitement Streaming avec Spark <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Partie 5 - Traitement Streaming avec Spark </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#spark-streaming class=md-nav__link> Spark Streaming </a> </li> <li class=md-nav__item> <a href=#environnement-et-code class=md-nav__link> Environnement et Code </a> </li> <li class=md-nav__item> <a href=#lancement-du-code-sur-le-cluster class=md-nav__link> Lancement du code sur le cluster </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#spark-streaming class=md-nav__link> Spark Streaming </a> </li> <li class=md-nav__item> <a href=#environnement-et-code class=md-nav__link> Environnement et Code </a> </li> <li class=md-nav__item> <a href=#lancement-du-code-sur-le-cluster class=md-nav__link> Lancement du code sur le cluster </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/formation-bigdata/edit/master/docs/tp5.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>Partie 5 - Traitement Streaming avec Spark</h1> <p><center><img src=../img/tp5/spark-streaming.png width=300></center></p> <h3 id=objectifs>Objectifs<a class=headerlink href=#objectifs title="Permanent link">&para;</a></h3> <p>Utilisation de Spark pour faire un traitement en streaming sur des données saisies au fur et à mesure sur le clavier. </p> <h3 id=spark-streaming>Spark Streaming<a class=headerlink href=#spark-streaming title="Permanent link">&para;</a></h3> <p>Spark est connu pour supporter également le traitement des données en streaming. Les données peuvent être lues à partir de plusieurs sources tel que Kafka, Flume, Kinesis ou des sockets TCP, et peuvent être traitées en utilisant des algorithmes complexes. Ensuite, les données traitées peuvent être stockées sur des systèmes de fichiers, des bases de données ou des dashboards. Il est même possible de réaliser des algorithmes de machine learning et de traitement de graphes sur les flux de données.</p> <p><center><img src=../img/tp5/streaming.jpeg width=400></center></p> <p>En interne, il fonctionne comme suit: Spark Streaming reçoit des données en streaming et les divise en micro-batches, qui sont ensuite traités par le moteur de spark pour générer le flux final de résultats.</p> <p><center><img src=../img/tp5/micro-batch.png width=500></center></p> <h3 id=environnement-et-code>Environnement et Code<a class=headerlink href=#environnement-et-code title="Permanent link">&para;</a></h3> <p>Nous allons commencer par tester le streaming en local, comme d'habitude. Pour cela:</p> <ol> <li>Commencer par créer un nouveau projet Maven appelé <em>3-Spark-Streaming</em>, avec le fichier pom suivant: <div class=highlight><pre><span></span><code><span class=cp>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class=nt>&lt;project</span> <span class=na>xmlns=</span><span class=s>&quot;http://maven.apache.org/POM/4.0.0&quot;</span>
       <span class=na>xmlns:xsi=</span><span class=s>&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>
       <span class=na>xsi:schemaLocation=</span><span class=s>&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span><span class=nt>&gt;</span>
  <span class=nt>&lt;modelVersion&gt;</span>4.0.0<span class=nt>&lt;/modelVersion&gt;</span>

  <span class=nt>&lt;groupId&gt;</span>spark.streaming<span class=nt>&lt;/groupId&gt;</span>
  <span class=nt>&lt;artifactId&gt;</span>stream<span class=nt>&lt;/artifactId&gt;</span>
  <span class=nt>&lt;version&gt;</span>1<span class=nt>&lt;/version&gt;</span>

  <span class=nt>&lt;properties&gt;</span>
      <span class=nt>&lt;maven.compiler.source&gt;</span>1.8<span class=nt>&lt;/maven.compiler.source&gt;</span>
      <span class=nt>&lt;maven.compiler.target&gt;</span>1.8<span class=nt>&lt;/maven.compiler.target&gt;</span>
  <span class=nt>&lt;/properties&gt;</span>

  <span class=nt>&lt;dependencies&gt;</span>
      <span class=nt>&lt;dependency&gt;</span>
          <span class=nt>&lt;groupId&gt;</span>org.apache.spark<span class=nt>&lt;/groupId&gt;</span>
          <span class=nt>&lt;artifactId&gt;</span>spark-core_2.13<span class=nt>&lt;/artifactId&gt;</span>
          <span class=nt>&lt;version&gt;</span>3.5.0<span class=nt>&lt;/version&gt;</span>
      <span class=nt>&lt;/dependency&gt;</span>
      <span class=nt>&lt;dependency&gt;</span>
        <span class=nt>&lt;groupId&gt;</span>org.apache.spark<span class=nt>&lt;/groupId&gt;</span>
        <span class=nt>&lt;artifactId&gt;</span>spark-streaming_2.13<span class=nt>&lt;/artifactId&gt;</span>
        <span class=nt>&lt;version&gt;</span>3.5.0<span class=nt>&lt;/version&gt;</span>
    <span class=nt>&lt;/dependency&gt;</span>

  <span class=nt>&lt;/dependencies&gt;</span>
<span class=nt>&lt;/project&gt;</span>
</code></pre></div></li> <li>Créer une classe <em>spark.streaming.Stream</em> avec le code suivant:</li> </ol> <div class=highlight><pre><span></span><code><span class=kn>package</span> <span class=nn>spark.streaming</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>org.apache.spark.sql.Dataset</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.sql.Encoders</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.sql.SparkSession</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.sql.streaming.StreamingQuery</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.sql.streaming.StreamingQueryException</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.spark.sql.streaming.Trigger</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>java.util.concurrent.TimeoutException</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>java.util.Arrays</span><span class=p>;</span>

<span class=kd>public</span> <span class=kd>class</span> <span class=nc>Stream</span> <span class=p>{</span>
    <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=p>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=p>)</span> <span class=kd>throws</span> <span class=n>StreamingQueryException</span><span class=p>,</span> <span class=n>TimeoutException</span>  <span class=p>{</span>
        <span class=n>SparkSession</span> <span class=n>spark</span> <span class=o>=</span> <span class=n>SparkSession</span>
            <span class=p>.</span><span class=na>builder</span><span class=p>()</span>
            <span class=p>.</span><span class=na>appName</span><span class=p>(</span><span class=s>&quot;NetworkWordCount&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>master</span><span class=p>(</span><span class=s>&quot;local[*]&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>getOrCreate</span><span class=p>();</span>

        <span class=c1>// Créer un DataFrame représentant le flux de lignes d&#39;entrée de la connexion à localhost:9999</span>
        <span class=n>Dataset</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span> <span class=n>lines</span> <span class=o>=</span> <span class=n>spark</span>
            <span class=p>.</span><span class=na>readStream</span><span class=p>()</span>
            <span class=p>.</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;socket&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>option</span><span class=p>(</span><span class=s>&quot;host&quot;</span><span class=p>,</span> <span class=s>&quot;localhost&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>option</span><span class=p>(</span><span class=s>&quot;port&quot;</span><span class=p>,</span> <span class=mi>9999</span><span class=p>)</span>
            <span class=p>.</span><span class=na>load</span><span class=p>()</span>
            <span class=p>.</span><span class=na>as</span><span class=p>(</span><span class=n>Encoders</span><span class=p>.</span><span class=na>STRING</span><span class=p>());</span>

        <span class=c1>// Diviser les lignes en mots</span>
        <span class=n>Dataset</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span> <span class=n>words</span> <span class=o>=</span> <span class=n>lines</span><span class=p>.</span><span class=na>flatMap</span><span class=p>(</span>
            <span class=p>(</span><span class=n>String</span> <span class=n>x</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Arrays</span><span class=p>.</span><span class=na>asList</span><span class=p>(</span><span class=n>x</span><span class=p>.</span><span class=na>split</span><span class=p>(</span><span class=s>&quot; &quot;</span><span class=p>)).</span><span class=na>iterator</span><span class=p>(),</span>
            <span class=n>Encoders</span><span class=p>.</span><span class=na>STRING</span><span class=p>());</span>

        <span class=c1>// Compter le nombre de fois chaque mot a été trouvé</span>
        <span class=n>Dataset</span><span class=o>&lt;</span><span class=n>org</span><span class=p>.</span><span class=na>apache</span><span class=p>.</span><span class=na>spark</span><span class=p>.</span><span class=na>sql</span><span class=p>.</span><span class=na>Row</span><span class=o>&gt;</span> <span class=n>wordCounts</span> <span class=o>=</span> <span class=n>words</span><span class=p>.</span><span class=na>groupBy</span><span class=p>(</span><span class=s>&quot;value&quot;</span><span class=p>).</span><span class=na>count</span><span class=p>();</span>

        <span class=c1>// Lancer l&#39;exécution de la requête qui imprime les calculs en cours d&#39;exécution sur la console</span>
        <span class=n>StreamingQuery</span> <span class=n>query</span> <span class=o>=</span> <span class=n>wordCounts</span><span class=p>.</span><span class=na>writeStream</span><span class=p>()</span>
            <span class=p>.</span><span class=na>outputMode</span><span class=p>(</span><span class=s>&quot;complete&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>format</span><span class=p>(</span><span class=s>&quot;console&quot;</span><span class=p>)</span>
            <span class=p>.</span><span class=na>trigger</span><span class=p>(</span><span class=n>Trigger</span><span class=p>.</span><span class=na>ProcessingTime</span><span class=p>(</span><span class=s>&quot;1 second&quot;</span><span class=p>))</span>
            <span class=p>.</span><span class=na>start</span><span class=p>();</span>

        <span class=n>query</span><span class=p>.</span><span class=na>awaitTermination</span><span class=p>();</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <p>Ce code permet de calculer le nombre de mots dans un stream de données (provenant du port localhost:9999) chaque seconde. Dans sa version actuelle, Spark encourage l'utilisation de <em>Structured Streaming</em>, une API de haut niveau qui fournit un traitement plus efficace, et qui est construite au dessus de Spark SQL, en intégrant les structures DataFrame et Dataset.</p> <details class=info> <summary>Trigger Interval</summary> <p>Dans Spark Structured Streaming, le concept de microbatch est utilisé pour traiter les données en continu par petits lots incrémentaux. La durée de chaque micro-lot est configurable et détermine la fréquence de traitement des données en continu. Cette durée est appelée "intervalle de déclenchement". Si vous ne spécifiez pas explicitement d'intervalle de déclenchement, le trigger par défaut est <em>ProcessingTime(0)</em>, qui est aussi connu comme le mode de traitement par micro-lots. Ce paramètre par défaut signifie que Spark essaiera de traiter les données aussi rapidement que possible, sans délai fixe entre les micro-lots.</p> </details> <h3 id=lancement-du-code-sur-le-cluster>Lancement du code sur le cluster<a class=headerlink href=#lancement-du-code-sur-le-cluster title="Permanent link">&para;</a></h3> <!-- Pour lancer le code précédent sur le cluster, il faudra d'abord faire une petite modification: **changer la valeur _localhost_ par l'IP de votre machine hote** (celle que vous utilisez pour lancer la commande _nc_).  --> <p>Nous allons directement lancer le code sur le cluster, car nous allons utiliser une petite commande utilitaire qui se trouve dans la majorité des systèmes Unix-like: <code>netcat</code>.</p> <ul> <li>Générer le fichier jar.</li> <li>Copier le fichier jar sur le contenaire master. On l'appellera <code>stream.jar</code></li> <li>Installer la commande netcat sur le contenaire master comme suit:<ul> <li>D'abord, faire un update de la liste ds packages sur votre contenaire: <div class=highlight><pre><span></span><code>apt update
</code></pre></div></li> <li>Ensuite, installer netcat: <div class=highlight><pre><span></span><code>apt install netcat
</code></pre></div></li> </ul> </li> <li>Ouvrir un nouveau terminal sur votre contenaire master, et taper la commande suivante pour créer le stream: <div class=highlight><pre><span></span><code>  nc -lk <span class=m>9999</span>
</code></pre></div></li> <li>Revenez au premier terminal pour lancer votre fichier Jar. L'application sera en écoute sur localhost:9999. <div class=highlight><pre><span></span><code>spark-submit  --class spark.streaming.Stream --master <span class=nb>local</span> stream-1.jar &gt; out
</code></pre></div></li> <li>Commencer à écrire des messages sur la console de votre terminal (là où vous avez lancé la commande nc)</li> </ul> <p>Nous avons utilisé à la fin de la commande spark-submit la chaîne <code>&gt; out</code>, pour indiquer que la sortie de la commande sera enregistrée dans un fichier out. Une fois que vous aurez saisi le texte à tester, arrêter l'application (avec Ctrl-C), et afficher le contenu du fichier <em>out</em>. Vous trouverez normalement un résultat semblable au suivant:</p> <p><center><img src=../img/tp5/stream-result.png width=700></center></p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2024-05-19T16:48:14+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-05-19</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../tp4/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Partie 4 - Traitement par Lot avec Spark" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Partie 4 - Traitement par Lot avec Spark </div> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>