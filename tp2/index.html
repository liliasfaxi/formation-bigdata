<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Formation sur les Infrastructures Big Data"><meta name=author content="Lilia Sfaxi"><link href=http://liliasfaxi.github.io/formation-bigdata/tp2/ rel=canonical><link rel=icon href=../img/favicon.ico><meta name=generator content="mkdocs-1.2.3, mkdocs-material-8.1.10"><title>Partie 2 - Hadoop Map Reduce - Formation Big Data</title><link rel=stylesheet href=../assets/stylesheets/main.d6be258b.min.css><link rel=stylesheet href=../assets/stylesheets/palette.e6a45f82.min.css><meta name=theme-color content=#ef5552><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../css/timeago.css><link rel=stylesheet href=../stylesheets/extra.css><link rel=stylesheet href=../stylesheets/links.css><script>__md_scope=new URL("..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme data-md-color-primary=red data-md-color-accent=orange> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#objectifs class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title="Formation Big Data" class="md-header__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Formation Big Data </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Partie 2 - Hadoop Map Reduce </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title="Formation Big Data" class="md-nav__button md-logo" aria-label="Formation Big Data" data-md-component=logo> <img src=../img/logo.png alt=logo> </a> Formation Big Data </label> <div class=md-nav__source> <a href=https://github.com/liliasfaxi/formation-bigdata/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> liliasfaxi/formation-bigdata </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../tp1/ class=md-nav__link> Partie 1 - Hadoop HDFS </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Partie 2 - Hadoop Map Reduce <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Partie 2 - Hadoop Map Reduce </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#presentation-de-map-reduce class=md-nav__link> Présentation de Map Reduce </a> </li> <li class=md-nav__item> <a href=#wordcount class=md-nav__link> Wordcount </a> <nav class=md-nav aria-label=Wordcount> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tester-wordcount class=md-nav__link> Tester Wordcount </a> </li> <li class=md-nav__item> <a href=#wordcount-avec-java class=md-nav__link> Wordcount avec Java </a> <nav class=md-nav aria-label="Wordcount avec Java"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tester-map-reduce-en-local class=md-nav__link> Tester Map Reduce en local </a> </li> <li class=md-nav__item> <a href=#lancer-map-reduce-sur-le-cluster class=md-nav__link> Lancer Map Reduce sur le cluster </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../tp3/ class=md-nav__link> Partie 3 - Spark Shell </a> </li> <li class=md-nav__item> <a href=../tp4/ class=md-nav__link> Partie 4 - Traitement par Lot avec Spark </a> </li> <li class=md-nav__item> <a href=../tp5/ class=md-nav__link> Partie 5 - Traitement Streaming avec Spark </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#objectifs class=md-nav__link> Objectifs </a> </li> <li class=md-nav__item> <a href=#presentation-de-map-reduce class=md-nav__link> Présentation de Map Reduce </a> </li> <li class=md-nav__item> <a href=#wordcount class=md-nav__link> Wordcount </a> <nav class=md-nav aria-label=Wordcount> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tester-wordcount class=md-nav__link> Tester Wordcount </a> </li> <li class=md-nav__item> <a href=#wordcount-avec-java class=md-nav__link> Wordcount avec Java </a> <nav class=md-nav aria-label="Wordcount avec Java"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#tester-map-reduce-en-local class=md-nav__link> Tester Map Reduce en local </a> </li> <li class=md-nav__item> <a href=#lancer-map-reduce-sur-le-cluster class=md-nav__link> Lancer Map Reduce sur le cluster </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/liliasfaxi/formation-bigdata/edit/master/docs/tp2.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>Partie 2 - Hadoop Map Reduce</h1> <p><center><img alt="Hadoop Map Reduce" src=../img/tp2/hadoop-mapreduce.png></center></p> <h3 id=objectifs>Objectifs<a class=headerlink href=#objectifs title="Permanent link">&para;</a></h3> <p>Initiation à Hadoop Map Reduce. Utilisation d'un code prédéfini et manipulation de l'API avec Java.</p> <h3 id=presentation-de-map-reduce>Présentation de Map Reduce<a class=headerlink href=#presentation-de-map-reduce title="Permanent link">&para;</a></h3> <p>Un Job Map-Reduce se compose principalement de deux types de programmes:</p> <ul> <li><strong>Mappers</strong> : permettent d’extraire les données nécessaires sous forme de clef/valeur, pour pouvoir ensuite les trier selon la clef</li> <li><strong>Reducers</strong> : prennent un ensemble de données triées selon leur clef, et effectuent le traitement nécessaire sur ces données (somme, moyenne, total...)</li> </ul> <h3 id=wordcount>Wordcount<a class=headerlink href=#wordcount title="Permanent link">&para;</a></h3> <p>Nous allons tester un programme MapReduce grâce à un exemple très simple, le <em>WordCount</em>, l'équivalent du <em>HelloWorld</em> pour les applications de traitement de données. Le Wordcount permet de calculer le nombre de mots dans un fichier donné, en décomposant le calcul en deux étapes:</p> <ul> <li>L'étape de <em>Mapping</em>, qui permet de découper le texte en mots et de délivrer en sortie un flux textuel, où chaque ligne contient le mot trouvé, suivi de la valeur 1 (pour dire que le mot a été trouvé une fois)</li> <li>L'étape de <em>Reducing</em>, qui permet de faire la somme des 1 pour chaque mot, pour trouver le nombre total d'occurrences de ce mot dans le texte.</li> </ul> <h4 id=tester-wordcount>Tester Wordcount<a class=headerlink href=#tester-wordcount title="Permanent link">&para;</a></h4> <p>Nous commençons par tester la bonne exécution d'un code Map Reduce prédéfini, en faisant appel à un exemple de wordcount fourni par le framework Hadoop. Pour cela:</p> <ul> <li>Commencer par créer un répertoire test dans votre contenaire master: <div class=highlight><pre><span></span><code>mkdir <span class=nb>test</span>
</code></pre></div></li> <li>Créer deux fichiers <code>file1</code> et <code>file2</code> dans <code>test</code> contenant chacun une ligne de texte, comme suit: <div class=highlight><pre><span></span><code><span class=nb>echo</span> <span class=s2>&quot;Hello Docker&quot;</span> &gt;test/file2.txt
<span class=nb>echo</span> <span class=s2>&quot;Hello Hadoop&quot;</span> &gt;test/file1.txt
</code></pre></div></li> <li>Créer un répertoire <code>test</code> dans HDFS, et y charger les deux fichiers: <div class=highlight><pre><span></span><code>hdfs dfs -mkdir <span class=nb>test</span>
hdfs dfs -put ./test/* <span class=nb>test</span>
</code></pre></div></li> <li>Lancer le job Wordcount en faisant appel au fichier jar prédéfini de Hadoop. Le résultat sera enregistré dans le répertoire <code>outest</code> de HDFS: <div class=highlight><pre><span></span><code>hadoop jar <span class=nv>$HADOOP_HOME</span>/share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-3.3.6-sources.jar org.apache.hadoop.examples.WordCount <span class=nb>test</span> outest
</code></pre></div></li> <li>Le job va se lancer, en affichant plusieurs lignes sur le terminal. On pourra visualiser le résultat en tapant les lignes suivantes: <div class=highlight><pre><span></span><code><span class=c1># Afficher les fichiers en entrée</span>
<span class=nb>echo</span> -e <span class=s2>&quot;\nEntrée - file1.txt:&quot;</span>
hdfs dfs -cat test/file1.txt

<span class=nb>echo</span> -e <span class=s2>&quot;\nEntrée - file2.txt:&quot;</span>
hdfs dfs -cat test/file2.txt

<span class=c1># afficher le résultat </span>
<span class=nb>echo</span> -e <span class=s2>&quot;\nSortie:&quot;</span>
hdfs dfs -cat outest/part-r-00000
</code></pre></div> Le résultat sera le suivant: <center> <img alt="Test de MapReduce" src=../img/tp2/test-mapreduce.png> </center> </li> </ul> <h4 id=wordcount-avec-java>Wordcount avec Java<a class=headerlink href=#wordcount-avec-java title="Permanent link">&para;</a></h4> <p>Commençons par créer un projet Maven dans IntelliJ IDEA. <strong>Nous utiliserons dans notre cas JDK 1.8</strong>.</p> <details class=info> <summary>Version de JDK</summary> <p>Ceci n'est pas une suggestion: l'utilisation d'une autre version que 1.8 provoquera des erreurs sans fin. Hadoop est compilé avec cette version de Java, connue pour sa stabilité. </p> </details> <p>Pour créer un projet Maven dans IntelliJIDEA: </p> <ul> <li>Créer un nouveau projet en cliquant sur <code>Maven</code> dans la fenêtre de gauche, et en choisissant le SDK 1.8 dans la fenêtre déroulante. <img alt="Nouveau Projet Maven" src=../img/tp2/nouveau-maven.png></li> <li>Nommer votre projet <code>1-Hadoop-MapReduce</code>, et définir les valeurs suivantes dans la partie <code>Artifact Coordinates</code>:<ul> <li><strong>GroupId</strong>: hadoop.mapreduce</li> <li><strong>ArtifactId</strong>: wordcount</li> <li><strong>Version</strong>: 1</li> </ul> </li> <li>Ouvrir le fichier <em>pom.xml</em> automatiquement créé, et remplacer son contenu par le code suivant:</li> </ul> <div class=highlight><pre><span></span><code>  <span class=cp>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class=nt>&lt;project</span> <span class=na>xmlns=</span><span class=s>&quot;http://maven.apache.org/POM/4.0.0&quot;</span>
         <span class=na>xmlns:xsi=</span><span class=s>&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span>
         <span class=na>xsi:schemaLocation=</span><span class=s>&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span><span class=nt>&gt;</span>
    <span class=nt>&lt;modelVersion&gt;</span>4.0.0<span class=nt>&lt;/modelVersion&gt;</span>

    <span class=nt>&lt;groupId&gt;</span>hadoop.mapreduce<span class=nt>&lt;/groupId&gt;</span>
    <span class=nt>&lt;artifactId&gt;</span>wordcount<span class=nt>&lt;/artifactId&gt;</span>
    <span class=nt>&lt;version&gt;</span>1<span class=nt>&lt;/version&gt;</span>

    <span class=nt>&lt;properties&gt;</span>
        <span class=nt>&lt;maven.compiler.source&gt;</span>1.8<span class=nt>&lt;/maven.compiler.source&gt;</span>
        <span class=nt>&lt;maven.compiler.target&gt;</span>1.8<span class=nt>&lt;/maven.compiler.target&gt;</span>
    <span class=nt>&lt;/properties&gt;</span>

    <span class=nt>&lt;dependencies&gt;</span>
        <span class=cm>&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;</span>
        <span class=nt>&lt;dependency&gt;</span>
            <span class=nt>&lt;groupId&gt;</span>org.apache.hadoop<span class=nt>&lt;/groupId&gt;</span>
            <span class=nt>&lt;artifactId&gt;</span>hadoop-common<span class=nt>&lt;/artifactId&gt;</span>
            <span class=nt>&lt;version&gt;</span>3.3.6<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;/dependency&gt;</span>
        <span class=cm>&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-core --&gt;</span>
        <span class=nt>&lt;dependency&gt;</span>
            <span class=nt>&lt;groupId&gt;</span>org.apache.hadoop<span class=nt>&lt;/groupId&gt;</span>
            <span class=nt>&lt;artifactId&gt;</span>hadoop-mapreduce-client-core<span class=nt>&lt;/artifactId&gt;</span>
            <span class=nt>&lt;version&gt;</span>3.3.6<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;/dependency&gt;</span>
        <span class=cm>&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs --&gt;</span>
        <span class=nt>&lt;dependency&gt;</span>
            <span class=nt>&lt;groupId&gt;</span>org.apache.hadoop<span class=nt>&lt;/groupId&gt;</span>
            <span class=nt>&lt;artifactId&gt;</span>hadoop-hdfs<span class=nt>&lt;/artifactId&gt;</span>
            <span class=nt>&lt;version&gt;</span>3.3.6<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;/dependency&gt;</span>
        <span class=cm>&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-common --&gt;</span>
        <span class=nt>&lt;dependency&gt;</span>
            <span class=nt>&lt;groupId&gt;</span>org.apache.hadoop<span class=nt>&lt;/groupId&gt;</span>
            <span class=nt>&lt;artifactId&gt;</span>hadoop-mapreduce-client-common<span class=nt>&lt;/artifactId&gt;</span>
            <span class=nt>&lt;version&gt;</span>3.3.6<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;/dependency&gt;</span>
        <span class=cm>&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-mapreduce-client-jobclient --&gt;</span>
        <span class=nt>&lt;dependency&gt;</span>
            <span class=nt>&lt;groupId&gt;</span>org.apache.hadoop<span class=nt>&lt;/groupId&gt;</span>
            <span class=nt>&lt;artifactId&gt;</span>hadoop-mapreduce-client-jobclient<span class=nt>&lt;/artifactId&gt;</span>
            <span class=nt>&lt;version&gt;</span>3.3.6<span class=nt>&lt;/version&gt;</span>
        <span class=nt>&lt;/dependency&gt;</span>

    <span class=nt>&lt;/dependencies&gt;</span>
  <span class=nt>&lt;/project&gt;</span>
</code></pre></div> <ul> <li>Créer un package <em>mapreduce</em> sous le répertoire <em>src/main/java/</em></li> <li>Créer la classe <em>TokenizerMapper</em>, contenant ce code:</li> </ul> <p><div class=highlight><pre><span></span><code>  <span class=kn>package</span> <span class=nn>mapreduce</span><span class=p>;</span>

  <span class=kn>import</span> <span class=nn>org.apache.hadoop.io.IntWritable</span><span class=p>;</span>
  <span class=kn>import</span> <span class=nn>org.apache.hadoop.io.Text</span><span class=p>;</span>
  <span class=kn>import</span> <span class=nn>org.apache.hadoop.mapreduce.Mapper</span><span class=p>;</span>

  <span class=kn>import</span> <span class=nn>java.io.IOException</span><span class=p>;</span>
  <span class=kn>import</span> <span class=nn>java.util.StringTokenizer</span><span class=p>;</span>

  <span class=kd>public</span> <span class=kd>class</span> <span class=nc>TokenizerMapper</span>
        <span class=kd>extends</span> <span class=n>Mapper</span><span class=o>&lt;</span><span class=n>Object</span><span class=p>,</span> <span class=n>Text</span><span class=p>,</span> <span class=n>Text</span><span class=p>,</span> <span class=n>IntWritable</span><span class=o>&gt;</span><span class=p>{</span>

    <span class=kd>private</span> <span class=kd>final</span> <span class=kd>static</span> <span class=n>IntWritable</span> <span class=n>one</span> <span class=o>=</span> <span class=k>new</span> <span class=n>IntWritable</span><span class=p>(</span><span class=mi>1</span><span class=p>);</span>
    <span class=kd>private</span> <span class=n>Text</span> <span class=n>word</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Text</span><span class=p>();</span>

    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>map</span><span class=p>(</span><span class=n>Object</span> <span class=n>key</span><span class=p>,</span> <span class=n>Text</span> <span class=n>value</span><span class=p>,</span> <span class=n>Mapper</span><span class=p>.</span><span class=na>Context</span> <span class=n>context</span>
    <span class=p>)</span> <span class=kd>throws</span> <span class=n>IOException</span><span class=p>,</span> <span class=n>InterruptedException</span> <span class=p>{</span>
        <span class=n>StringTokenizer</span> <span class=n>itr</span> <span class=o>=</span> <span class=k>new</span> <span class=n>StringTokenizer</span><span class=p>(</span><span class=n>value</span><span class=p>.</span><span class=na>toString</span><span class=p>());</span>
        <span class=k>while</span> <span class=p>(</span><span class=n>itr</span><span class=p>.</span><span class=na>hasMoreTokens</span><span class=p>())</span> <span class=p>{</span>
            <span class=n>word</span><span class=p>.</span><span class=na>set</span><span class=p>(</span><span class=n>itr</span><span class=p>.</span><span class=na>nextToken</span><span class=p>());</span>
            <span class=n>context</span><span class=p>.</span><span class=na>write</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=n>one</span><span class=p>);</span>
        <span class=p>}</span>
    <span class=p>}</span>
  <span class=p>}</span>
</code></pre></div> La méthode <code>map</code> manipule une ligne d'entrée (<em>value</em>), commence par la diviser en mots grâce à la classe <em>StringTokenizer</em>, ensuite, pour chaque mot, elle renvoie en sortie (dans l'object global <em>context</em>) ce mot accompagné de la valeur <strong>1</strong>.</p> <ul> <li>Créer la classe <em>IntSumReducer</em>:</li> </ul> <p><div class=highlight><pre><span></span><code><span class=kn>package</span> <span class=nn>mapreduce</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>org.apache.hadoop.io.IntWritable</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.io.Text</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.mapreduce.Reducer</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>java.io.IOException</span><span class=p>;</span>

<span class=kd>public</span> <span class=kd>class</span> <span class=nc>IntSumReducer</span>
        <span class=kd>extends</span> <span class=n>Reducer</span><span class=o>&lt;</span><span class=n>Text</span><span class=p>,</span><span class=n>IntWritable</span><span class=p>,</span><span class=n>Text</span><span class=p>,</span><span class=n>IntWritable</span><span class=o>&gt;</span> <span class=p>{</span>

    <span class=kd>private</span> <span class=n>IntWritable</span> <span class=n>result</span> <span class=o>=</span> <span class=k>new</span> <span class=n>IntWritable</span><span class=p>();</span>

    <span class=kd>public</span> <span class=kt>void</span> <span class=nf>reduce</span><span class=p>(</span><span class=n>Text</span> <span class=n>key</span><span class=p>,</span> <span class=n>Iterable</span><span class=o>&lt;</span><span class=n>IntWritable</span><span class=o>&gt;</span> <span class=n>values</span><span class=p>,</span>
                       <span class=n>Context</span> <span class=n>context</span>
    <span class=p>)</span> <span class=kd>throws</span> <span class=n>IOException</span><span class=p>,</span> <span class=n>InterruptedException</span> <span class=p>{</span>
        <span class=kt>int</span> <span class=n>sum</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
        <span class=k>for</span> <span class=p>(</span><span class=n>IntWritable</span> <span class=n>val</span> <span class=p>:</span> <span class=n>values</span><span class=p>)</span> <span class=p>{</span>
            <span class=n>System</span><span class=p>.</span><span class=na>out</span><span class=p>.</span><span class=na>println</span><span class=p>(</span><span class=s>&quot;value: &quot;</span><span class=o>+</span><span class=n>val</span><span class=p>.</span><span class=na>get</span><span class=p>());</span>
            <span class=n>sum</span> <span class=o>+=</span> <span class=n>val</span><span class=p>.</span><span class=na>get</span><span class=p>();</span>
        <span class=p>}</span>
        <span class=n>System</span><span class=p>.</span><span class=na>out</span><span class=p>.</span><span class=na>println</span><span class=p>(</span><span class=s>&quot;--&gt; Sum = &quot;</span><span class=o>+</span><span class=n>sum</span><span class=p>);</span>
        <span class=n>result</span><span class=p>.</span><span class=na>set</span><span class=p>(</span><span class=n>sum</span><span class=p>);</span>
        <span class=n>context</span><span class=p>.</span><span class=na>write</span><span class=p>(</span><span class=n>key</span><span class=p>,</span> <span class=n>result</span><span class=p>);</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> La méthode <code>reduce</code> reçoit en entrée un couple clef/valeurs. En effet, Hadoop se charge, en arrière plan dans son étape de <em>Shuffle and Sort</em> de regrouper les éléments en sortie du Mapper, ayant la même clef, ainsi que leurs différentes valeurs. Par exemple, si le mot Bonjour existe sur deux lignes différentes en sortie des Mappers, il arrive au reducer sous la forme : <code>Bonjour 1 1</code>. Ce reducer se charge alors de parcourir les valeurs associés à la même clef, puis de faire leurs sommes.</p> <ul> <li>Enfin, créer la classe principale <em>WordCount</em>:</li> </ul> <p><div class=highlight><pre><span></span><code><span class=kn>package</span> <span class=nn>mapreduce</span><span class=p>;</span>

<span class=kn>import</span> <span class=nn>org.apache.hadoop.conf.Configuration</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.fs.Path</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.io.IntWritable</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.io.Text</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.mapreduce.Job</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.mapreduce.lib.input.FileInputFormat</span><span class=p>;</span>
<span class=kn>import</span> <span class=nn>org.apache.hadoop.mapreduce.lib.output.FileOutputFormat</span><span class=p>;</span>

<span class=kd>public</span> <span class=kd>class</span> <span class=nc>WordCount</span> <span class=p>{</span>
    <span class=kd>public</span> <span class=kd>static</span> <span class=kt>void</span> <span class=nf>main</span><span class=p>(</span><span class=n>String</span><span class=o>[]</span> <span class=n>args</span><span class=p>)</span> <span class=kd>throws</span> <span class=n>Exception</span> <span class=p>{</span>
        <span class=n>Configuration</span> <span class=n>conf</span> <span class=o>=</span> <span class=k>new</span> <span class=n>Configuration</span><span class=p>();</span>
        <span class=n>Job</span> <span class=n>job</span> <span class=o>=</span> <span class=n>Job</span><span class=p>.</span><span class=na>getInstance</span><span class=p>(</span><span class=n>conf</span><span class=p>,</span> <span class=s>&quot;word count&quot;</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setJarByClass</span><span class=p>(</span><span class=n>WordCount</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setMapperClass</span><span class=p>(</span><span class=n>TokenizerMapper</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setCombinerClass</span><span class=p>(</span><span class=n>IntSumReducer</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setReducerClass</span><span class=p>(</span><span class=n>IntSumReducer</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setOutputKeyClass</span><span class=p>(</span><span class=n>Text</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>job</span><span class=p>.</span><span class=na>setOutputValueClass</span><span class=p>(</span><span class=n>IntWritable</span><span class=p>.</span><span class=na>class</span><span class=p>);</span>
        <span class=n>FileInputFormat</span><span class=p>.</span><span class=na>addInputPath</span><span class=p>(</span><span class=n>job</span><span class=p>,</span> <span class=k>new</span> <span class=n>Path</span><span class=p>(</span><span class=n>args</span><span class=o>[</span><span class=mi>0</span><span class=o>]</span><span class=p>));</span>
        <span class=n>FileOutputFormat</span><span class=p>.</span><span class=na>setOutputPath</span><span class=p>(</span><span class=n>job</span><span class=p>,</span> <span class=k>new</span> <span class=n>Path</span><span class=p>(</span><span class=n>args</span><span class=o>[</span><span class=mi>1</span><span class=o>]</span><span class=p>));</span>
        <span class=n>System</span><span class=p>.</span><span class=na>exit</span><span class=p>(</span><span class=n>job</span><span class=p>.</span><span class=na>waitForCompletion</span><span class=p>(</span><span class=kc>true</span><span class=p>)</span> <span class=o>?</span> <span class=mi>0</span> <span class=p>:</span> <span class=mi>1</span><span class=p>);</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div> Cette classe permet de lancer le Job en donnant les différentes configurations. Par exemple, elle déclare la classe <em>IntSumReducer</em> comme étant à la fois le reducer et le combiner du Job Map Reduce.</p> <h5 id=tester-map-reduce-en-local>Tester Map Reduce en local<a class=headerlink href=#tester-map-reduce-en-local title="Permanent link">&para;</a></h5> <p>Dans votre projet sur IntelliJ:</p> <ul> <li>Créer un répertoire <em>input</em> sous le répertoire <em>resources</em> de votre projet.</li> <li>Créer un fichier de test: <em>file.txt</em> dans lequel vous insèrerez les deux lignes: <div class=highlight><pre><span></span><code>Hello Wordcount!
Hello Hadoop!
</code></pre></div></li> <li>Nous allons maintenant définir des arguments de la méthode Main: le fichier en entrée sur lequel Map reduce va travailler, et le répertoire en sortie dans lequel le résultat sera stocké. Pour cela:<ul> <li>Cliquer sur le bouton <em>Add Configuration...</em> qui se trouve en haut à droite de votre fenêtre principale dans IntelliJ, ou alors aller vers le menu <em>Run -&gt; Edit Configurations...</em></li> <li>Cliquer sur le bouton + en haut à gauche de la fenêtre qui vient de s'ouvrir. </li> <li>Choisir <em>Application</em> dans la liste.</li> <li>Nommer votre configuration <em>local-run</em></li> <li>Dans la partie <em>Build and run</em>, prenez soin de choisir la version 1.8 de Java</li> <li>Choisir mapreduce.WordCount comme étant la <em>Main Class</em> à exécuter.</li> <li>Dans le champ <em>Program arguments</em>, saisir les arguments suivants: <code>src/main/resources/input/file.txt src/main/resources/output</code>. Nous indiquons ainsi que le répertoire output est le répertoire de sortie de notre exécution. ATTENTION, output ne doit pas exister avant le lancement du job.</li> <li>Voici la fenêtre de configuration finale: <img alt="Configuration locale de MapReduce" src=../img/tp2/config-locale.png></li> </ul> </li> <li>Lancer le programme. Un répertoire <em>output</em> sera créé dans le répertoire <em>resources</em>, contenant notamment un fichier <em>part-r-00000</em>, dont le contenu devrait être le suivant:</li> </ul> <div class=highlight><pre><span></span><code>Hadoop!   1
Hello 2
Wordcount!    1
</code></pre></div> <details class=bug> <summary>Pour les utilisateurs.trices de Windows</summary> <p>Les utilisateurs.trices de Windows vont certainement rencontrer l'erreur suivante: <code>HADOOP_HOME and hadoop.home.dir are unset.</code>. Pour y remédier, suivre les étapes suivantes:</p> <ul> <li>Télécharger de ce <a href=https://github.com/cdarlint/winutils>projet</a> le répertoire correspondant à la version de Hadoop utilisée (ici 3.3.6) quelque part sur votre machine. Appelons ce quelque part <em>REP</em>.</li> <li>Créer la variable d'environnement HADOOP_HOME aux variables système, et y associer la valeur <em>REP</em></li> <li>Ajouter à la variable d'environnement PATH le répertoire <code>$HADOOP_HOME/bin</code> Sinon, vous pouvez toujours utiliser Linux.. </li> </ul> </details> <h5 id=lancer-map-reduce-sur-le-cluster>Lancer Map Reduce sur le cluster<a class=headerlink href=#lancer-map-reduce-sur-le-cluster title="Permanent link">&para;</a></h5> <p>Dans votre projet IntelliJ:</p> <ul> <li>Pour pouvoir encapsuler toutes les dépendances du projet dans le fichier JAR à exporter, ajouter les lignes suivantes dans le fichier <em>pom.xml</em> de votre projet, juste après les dépendances:</li> </ul> <div class=highlight><pre><span></span><code><span class=nt>&lt;build&gt;</span>
  <span class=nt>&lt;plugins&gt;</span>
    <span class=nt>&lt;plugin&gt;</span>
      <span class=nt>&lt;groupId&gt;</span>org.apache.maven.plugins<span class=nt>&lt;/groupId&gt;</span>
      <span class=nt>&lt;artifactId&gt;</span>maven-assembly-plugin<span class=nt>&lt;/artifactId&gt;</span>
      <span class=nt>&lt;version&gt;</span>3.6.0<span class=nt>&lt;/version&gt;</span> <span class=cm>&lt;!-- Use latest version --&gt;</span>
      <span class=nt>&lt;configuration&gt;</span>
        <span class=nt>&lt;archive&gt;</span>
          <span class=nt>&lt;manifest&gt;</span>
<span class=hll>            <span class=nt>&lt;mainClass&gt;</span>mapreduce.WordCount<span class=nt>&lt;/mainClass&gt;</span>
</span>          <span class=nt>&lt;/manifest&gt;</span>
        <span class=nt>&lt;/archive&gt;</span>
        <span class=nt>&lt;descriptorRefs&gt;</span>
          <span class=nt>&lt;descriptorRef&gt;</span>jar-with-dependencies<span class=nt>&lt;/descriptorRef&gt;</span>
        <span class=nt>&lt;/descriptorRefs&gt;</span>
      <span class=nt>&lt;/configuration&gt;</span>
      <span class=nt>&lt;executions&gt;</span>
        <span class=nt>&lt;execution&gt;</span>
          <span class=nt>&lt;id&gt;</span>make-assembly<span class=nt>&lt;/id&gt;</span> <span class=cm>&lt;!-- this is used for inheritance merges --&gt;</span>
          <span class=nt>&lt;phase&gt;</span>package<span class=nt>&lt;/phase&gt;</span> <span class=cm>&lt;!-- bind to the packaging phase --&gt;</span>
          <span class=nt>&lt;goals&gt;</span>
            <span class=nt>&lt;goal&gt;</span>single<span class=nt>&lt;/goal&gt;</span>
          <span class=nt>&lt;/goals&gt;</span>
        <span class=nt>&lt;/execution&gt;</span>
      <span class=nt>&lt;/executions&gt;</span>
    <span class=nt>&lt;/plugin&gt;</span>
  <span class=nt>&lt;/plugins&gt;</span>
<span class=nt>&lt;/build&gt;</span>
</code></pre></div> <ul> <li>Créer une nouvelle configuration d'exécution, cette fois-ci de type Maven, qu'on appellera <em>wordcount-jar</em>, et qui va exécuter la commande <em>package</em> pour créer un nouveau fichier jar exécutable à partir de notre code. La configuration sera comme suit: <img alt="Configuration Maven Package" src=../img/tp2/maven-package.png></li> <li>Lancer la configuration. Un fichier <em>wordcount-1-jar-with-dependencies.jar</em> sera créé sous le répertoire <em>target</em> du projet.</li> <li> <p>Copier le fichier jar créé dans le contenaire master. Pour cela:</p> <ul> <li>Ouvrir le terminal sur le répertoire du projet. Cela peut être fait avec IntelliJ en ouvrant directement un terminal.</li> <li>Taper la commande suivante: <div class=highlight><pre><span></span><code>docker cp target/wordcount-1-jar-with-dependencies.jar hadoop-master:/root/wordcount.jar
</code></pre></div></li> </ul> </li> <li> <p>Revenir au shell du contenaire master, et lancer le job map reduce avec cette commande:</p> </li> </ul> <div class=highlight><pre><span></span><code>hadoop jar wordcount.jar input output
</code></pre></div> <p>Le Job sera lancé sur le fichier <em>purchases.txt</em> que vous aviez préalablement chargé dans le répertoire <em>input</em> de HDFS. Une fois le Job terminé, un répertoire <em>output</em> sera créé. Si tout se passe bien, vous obtiendrez un affichage ressemblant au suivant: <img alt="Résultat Map Reduce" src=../img/tp2/resultat-mapreduce.png></p> <p>En affichant les dernières lignes du fichier généré <em>output/part-r-00000</em>, avec <code>hdfs dfs -tail output/part-r-00000</code>, vous obtiendrez l'affichage suivant:</p> <p><img alt="Affichage Map Reduce" src=../img/tp2/tail.png></p> <p>Il vous est possible de monitorer vos Jobs Map Reduce, en allant à la page: <code>http://localhost:8088</code>. Vous trouverez votre Job dans la liste des applications comme suit:</p> <p><img alt="Job MR" src=../img/tp2/job-mr.png></p> <p>Il est également possible de voir le comportement des noeuds workers, en allant à l'adresse: <code>http://localhost:8041</code> pour <em>worker1</em>, et <code>http://localhost:8042</code> pour <em>worker2</em>. Vous obtiendrez ce qui suit:</p> <p><img alt="Job MR" src=../img/tp2/worker-mr.png></p> <hr> <div class=md-source-file> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class=timeago datetime=2024-05-20T17:31:57+01:00 locale=en></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2024-05-20</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../tp1/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Partie 1 - Hadoop HDFS" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Partie 1 - Hadoop HDFS </div> </div> </a> <a href=../tp3/ class="md-footer__link md-footer__link--next" aria-label="Next: Partie 3 - Spark Shell" rel=next> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Next </span> Partie 3 - Spark Shell </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Lilia Sfaxi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.092fa1f6.min.js"}</script> <script src=../assets/javascripts/bundle.e3b2bf44.min.js></script> <script src=../js/timeago.min.js></script> <script src=../js/timeago_mkdocs_material.js></script> </body> </html>